{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U transformers accelerate peft bitsandbytes -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 23 17:47:02 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.02              Driver Version: 560.94         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:01:00.0  On |                  Off |\n",
      "|  0%   41C    P8              8W /  450W |     638MiB /  24564MiB |      3%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A        27      G   /Xwayland                                   N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_MODEL = \"HuggingFaceH4/zephyr-7b-alpha\"\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajneesh/miniconda3/envs/hf_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "import numpy  as np\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.environ['HF_HOME '] = '///mnt/c/Personal/Competitions/HFCache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb2cf5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Expert', 1: 'Novice', 2: 'Gemini', 3: 'GPT4', 4: 'Llama31405B', 5: 'Llama318B', 6: 'Mistral', 7: 'Phi3', 8: 'Sonnet'} {'Expert': 0, 'Novice': 1, 'Gemini': 2, 'GPT4': 3, 'Llama31405B': 4, 'Llama318B': 5, 'Mistral': 6, 'Phi3': 7, 'Sonnet': 8}\n"
     ]
    }
   ],
   "source": [
    "# Define the tutor classes\n",
    "TUTOR_CLASSES = [\n",
    "    \"Expert\",\n",
    "    \"Novice\",\n",
    "    \"Gemini\",\n",
    "    \"GPT4\",\n",
    "    \"Llama31405B\",\n",
    "    \"Llama318B\",\n",
    "    \"Mistral\",\n",
    "    \"Phi3\",\n",
    "    \"Sonnet\"\n",
    "]\n",
    "\n",
    "# Create label mappings\n",
    "id2label = {i: label for i, label in enumerate(TUTOR_CLASSES)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "print(id2label, label2id)\n",
    "\n",
    "MAX_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b5af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Processing Functions\n",
    "def load_data(dev_data_path='///mnt/c/Personal/Competitions/BEA_2025/data/mrbench_v3_devset.json'):\n",
    "    \"\"\"\n",
    "    Load development and (optionally) test datasets\n",
    "    \"\"\"\n",
    "    # Load development data\n",
    "    with open(dev_data_path, 'r') as f:\n",
    "        dev_data = json.load(f)\n",
    "    \n",
    "    # Process development data\n",
    "    dev_examples = []\n",
    "    for dialogue in dev_data:\n",
    "        conversation_id = dialogue[\"conversation_id\"]\n",
    "        conversation_history = dialogue[\"conversation_history\"]\n",
    "        \n",
    "        for tutor_id, tutor_data in dialogue[\"tutor_responses\"].items():\n",
    "            if tutor_id in TUTOR_CLASSES or any(cls_name in tutor_id for cls_name in TUTOR_CLASSES):\n",
    "                # Map the tutor_id to one of our classes\n",
    "                tutor_class = next((cls for cls in TUTOR_CLASSES if cls in tutor_id), tutor_id)\n",
    "                \n",
    "                dev_examples.append({\n",
    "                    \"conversation_id\": conversation_id,\n",
    "                    \"conversation_history\": conversation_history,\n",
    "                    \"tutor_response\": tutor_data[\"response\"],\n",
    "                    \"tutor_class\": tutor_class\n",
    "                })\n",
    "    \n",
    "\n",
    "    return dev_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.DataFrame(load_data())\n",
    "train['target'] = train['tutor_class'].map(label2id)\n",
    "train.rename(columns={'conversation_history':'Question','tutor_response':'Response'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d09386ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>Question</th>\n",
       "      <th>Response</th>\n",
       "      <th>tutor_class</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Now that we know the cost of 1 pound of meat i...</td>\n",
       "      <td>Llama318B</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>You're close, but I notice that you calculated...</td>\n",
       "      <td>Llama31405B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>That's correct. So, if 1 pound of meat costs $...</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>It seems like you've calculated the cost as if...</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            conversation_id  \\\n",
       "0  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "1  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "2  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "3  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "4  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Tutor: Hi, could you please provide a step-by-...   \n",
       "1  Tutor: Hi, could you please provide a step-by-...   \n",
       "2  Tutor: Hi, could you please provide a step-by-...   \n",
       "3  Tutor: Hi, could you please provide a step-by-...   \n",
       "4  Tutor: Hi, could you please provide a step-by-...   \n",
       "\n",
       "                                            Response  tutor_class  target  \n",
       "0  Great, you've correctly identified the cost of...       Sonnet       8  \n",
       "1  Now that we know the cost of 1 pound of meat i...    Llama318B       5  \n",
       "2  You're close, but I notice that you calculated...  Llama31405B       4  \n",
       "3  That's correct. So, if 1 pound of meat costs $...         GPT4       3  \n",
       "4  It seems like you've calculated the cost as if...      Mistral       6  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c978dfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2476, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i, row in train.iterrows():\n",
    "    question = row.Question\n",
    "    response = row.Response\n",
    "    convid = row.conversation_id\n",
    "    context = train[(train.conversation_id==convid)&(train.Response!=response)].Response.values\n",
    "    context = ' [SEP] '.join(context)\n",
    "    train.loc[i, 'context'] = context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08b0fb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2476, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4e0872c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2476, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_map = pd.read_csv('///mnt/c/Personal/Competitions/BEA_2025/debetav3_context_multisampleDropout/oofs.csv')\n",
    "fold_map.head(2)\n",
    "fold_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "125e45dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>Question</th>\n",
       "      <th>Response</th>\n",
       "      <th>tutor_class</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>8</td>\n",
       "      <td>Now that we know the cost of 1 pound of meat i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Now that we know the cost of 1 pound of meat i...</td>\n",
       "      <td>Llama318B</td>\n",
       "      <td>5</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>You're close, but I notice that you calculated...</td>\n",
       "      <td>Llama31405B</td>\n",
       "      <td>4</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>That's correct. So, if 1 pound of meat costs $...</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>3</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>It seems like you've calculated the cost as if...</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>6</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            conversation_id  \\\n",
       "0  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "1  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "2  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "3  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "4  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Tutor: Hi, could you please provide a step-by-...   \n",
       "1  Tutor: Hi, could you please provide a step-by-...   \n",
       "2  Tutor: Hi, could you please provide a step-by-...   \n",
       "3  Tutor: Hi, could you please provide a step-by-...   \n",
       "4  Tutor: Hi, could you please provide a step-by-...   \n",
       "\n",
       "                                            Response  tutor_class  target  \\\n",
       "0  Great, you've correctly identified the cost of...       Sonnet       8   \n",
       "1  Now that we know the cost of 1 pound of meat i...    Llama318B       5   \n",
       "2  You're close, but I notice that you calculated...  Llama31405B       4   \n",
       "3  That's correct. So, if 1 pound of meat costs $...         GPT4       3   \n",
       "4  It seems like you've calculated the cost as if...      Mistral       6   \n",
       "\n",
       "                                             context  \n",
       "0  Now that we know the cost of 1 pound of meat i...  \n",
       "1  Great, you've correctly identified the cost of...  \n",
       "2  Great, you've correctly identified the cost of...  \n",
       "3  Great, you've correctly identified the cost of...  \n",
       "4  Great, you've correctly identified the cost of...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad4116a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>Question</th>\n",
       "      <th>Response</th>\n",
       "      <th>tutor_class</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>fold</th>\n",
       "      <th>target_0</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "      <th>target_6</th>\n",
       "      <th>target_7</th>\n",
       "      <th>target_8</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>8</td>\n",
       "      <td>Now that we know the cost of 1 pound of meat i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>0.006057</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.980455</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Now that we know the cost of 1 pound of meat i...</td>\n",
       "      <td>Llama318B</td>\n",
       "      <td>5</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>0.994394</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>You're close, but I notice that you calculated...</td>\n",
       "      <td>Llama31405B</td>\n",
       "      <td>4</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.992729</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>That's correct. So, if 1 pound of meat costs $...</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>3</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.001449</td>\n",
       "      <td>0.983959</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>It seems like you've calculated the cost as if...</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>6</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.994973</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            conversation_id  \\\n",
       "0  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "1  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "2  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "3  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "4  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Tutor: Hi, could you please provide a step-by-...   \n",
       "1  Tutor: Hi, could you please provide a step-by-...   \n",
       "2  Tutor: Hi, could you please provide a step-by-...   \n",
       "3  Tutor: Hi, could you please provide a step-by-...   \n",
       "4  Tutor: Hi, could you please provide a step-by-...   \n",
       "\n",
       "                                            Response  tutor_class  target  \\\n",
       "0  Great, you've correctly identified the cost of...       Sonnet       8   \n",
       "1  Now that we know the cost of 1 pound of meat i...    Llama318B       5   \n",
       "2  You're close, but I notice that you calculated...  Llama31405B       4   \n",
       "3  That's correct. So, if 1 pound of meat costs $...         GPT4       3   \n",
       "4  It seems like you've calculated the cost as if...      Mistral       6   \n",
       "\n",
       "                                             context  fold  target_0  \\\n",
       "0  Now that we know the cost of 1 pound of meat i...     0  0.000430   \n",
       "1  Great, you've correctly identified the cost of...     0  0.000411   \n",
       "2  Great, you've correctly identified the cost of...     0  0.000498   \n",
       "3  Great, you've correctly identified the cost of...     0  0.004078   \n",
       "4  Great, you've correctly identified the cost of...     0  0.000712   \n",
       "\n",
       "   target_1  target_2  target_3  target_4  target_5  target_6  target_7  \\\n",
       "0  0.000975  0.004653  0.000990  0.001670  0.003360  0.006057  0.001408   \n",
       "1  0.000347  0.000558  0.000706  0.001815  0.994394  0.000382  0.000257   \n",
       "2  0.000256  0.000300  0.000437  0.992729  0.004073  0.000793  0.000214   \n",
       "3  0.000667  0.001449  0.983959  0.001099  0.005142  0.001323  0.001366   \n",
       "4  0.000428  0.001301  0.000389  0.000633  0.000496  0.994973  0.000704   \n",
       "\n",
       "   target_8  pred  \n",
       "0  0.980455     8  \n",
       "1  0.001131     5  \n",
       "2  0.000700     4  \n",
       "3  0.000917     3  \n",
       "4  0.000364     6  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "980a909e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>Question</th>\n",
       "      <th>Response</th>\n",
       "      <th>tutor_class</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>8</td>\n",
       "      <td>Now that we know the cost of 1 pound of meat i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Now that we know the cost of 1 pound of meat i...</td>\n",
       "      <td>Llama318B</td>\n",
       "      <td>5</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>You're close, but I notice that you calculated...</td>\n",
       "      <td>Llama31405B</td>\n",
       "      <td>4</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>That's correct. So, if 1 pound of meat costs $...</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>3</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>It seems like you've calculated the cost as if...</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>6</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            conversation_id  \\\n",
       "0  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "1  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "2  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "3  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "4  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Tutor: Hi, could you please provide a step-by-...   \n",
       "1  Tutor: Hi, could you please provide a step-by-...   \n",
       "2  Tutor: Hi, could you please provide a step-by-...   \n",
       "3  Tutor: Hi, could you please provide a step-by-...   \n",
       "4  Tutor: Hi, could you please provide a step-by-...   \n",
       "\n",
       "                                            Response  tutor_class  target  \\\n",
       "0  Great, you've correctly identified the cost of...       Sonnet       8   \n",
       "1  Now that we know the cost of 1 pound of meat i...    Llama318B       5   \n",
       "2  You're close, but I notice that you calculated...  Llama31405B       4   \n",
       "3  That's correct. So, if 1 pound of meat costs $...         GPT4       3   \n",
       "4  It seems like you've calculated the cost as if...      Mistral       6   \n",
       "\n",
       "                                             context  fold  \n",
       "0  Now that we know the cost of 1 pound of meat i...     0  \n",
       "1  Great, you've correctly identified the cost of...     0  \n",
       "2  Great, you've correctly identified the cost of...     0  \n",
       "3  Great, you've correctly identified the cost of...     0  \n",
       "4  Great, you've correctly identified the cost of...     0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.merge(train,fold_map[['conversation_id','fold','tutor_class']],on=['conversation_id','tutor_class'], how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7e5fd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "2    497\n",
       "4    496\n",
       "3    495\n",
       "0    494\n",
       "1    494\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['fold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20ad9cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2476, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GroupKFold\n",
    "# folds = GroupKFold(n_splits=5, shuffle=False)\n",
    "# train['fold'] = -1\n",
    "# for i,(train_index, test_index) in enumerate(folds.split(train,train['target'], groups=train['Question'])): \n",
    "#     train.loc[test_index,'fold'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['input'] = \"Question: \" + train['Question'] + '; Answer: ' + train['Response'] #+ '; Context: ' + train[\"context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.rename(columns={'target': 'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cb5149f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>Question</th>\n",
       "      <th>Response</th>\n",
       "      <th>tutor_class</th>\n",
       "      <th>label</th>\n",
       "      <th>context</th>\n",
       "      <th>fold</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>8</td>\n",
       "      <td>Now that we know the cost of 1 pound of meat i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Tutor: Hi, could you please provide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Now that we know the cost of 1 pound of meat i...</td>\n",
       "      <td>Llama318B</td>\n",
       "      <td>5</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Tutor: Hi, could you please provide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>You're close, but I notice that you calculated...</td>\n",
       "      <td>Llama31405B</td>\n",
       "      <td>4</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Tutor: Hi, could you please provide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>That's correct. So, if 1 pound of meat costs $...</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>3</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Tutor: Hi, could you please provide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>It seems like you've calculated the cost as if...</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>6</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Tutor: Hi, could you please provide ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            conversation_id  \\\n",
       "0  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "1  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "2  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "3  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "4  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Tutor: Hi, could you please provide a step-by-...   \n",
       "1  Tutor: Hi, could you please provide a step-by-...   \n",
       "2  Tutor: Hi, could you please provide a step-by-...   \n",
       "3  Tutor: Hi, could you please provide a step-by-...   \n",
       "4  Tutor: Hi, could you please provide a step-by-...   \n",
       "\n",
       "                                            Response  tutor_class  label  \\\n",
       "0  Great, you've correctly identified the cost of...       Sonnet      8   \n",
       "1  Now that we know the cost of 1 pound of meat i...    Llama318B      5   \n",
       "2  You're close, but I notice that you calculated...  Llama31405B      4   \n",
       "3  That's correct. So, if 1 pound of meat costs $...         GPT4      3   \n",
       "4  It seems like you've calculated the cost as if...      Mistral      6   \n",
       "\n",
       "                                             context  fold  \\\n",
       "0  Now that we know the cost of 1 pound of meat i...     0   \n",
       "1  Great, you've correctly identified the cost of...     0   \n",
       "2  Great, you've correctly identified the cost of...     0   \n",
       "3  Great, you've correctly identified the cost of...     0   \n",
       "4  Great, you've correctly identified the cost of...     0   \n",
       "\n",
       "                                               input  \n",
       "0  Question: Tutor: Hi, could you please provide ...  \n",
       "1  Question: Tutor: Hi, could you please provide ...  \n",
       "2  Question: Tutor: Hi, could you please provide ...  \n",
       "3  Question: Tutor: Hi, could you please provide ...  \n",
       "4  Question: Tutor: Hi, could you please provide ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model with 4bit bnb\n",
    "\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType # type: ignore\n",
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, LlamaForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(TARGET_MODEL, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f49c8980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        \n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            print(_)\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, max_length=MAX_LEN):\n",
    "    return tokenizer(examples[\"input\"], truncation=True, max_length=max_length, padding=True)\n",
    "    # return tokenizer(examples[\"input\"], \n",
    "    #                 #  text_target = examples['label'],\n",
    "    #                  truncation=True, \n",
    "    #                  max_length=max_length, \n",
    "    #                  padding=\"max_length\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = evaluate.load(\"accuracy\")\n",
    "    f1 = evaluate.load(\"f1\")\n",
    "    \n",
    "    accuracy_score = accuracy.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    \n",
    "    # Add per-class F1 scores\n",
    "    f1_per_class = f1.compute(predictions=predictions, references=labels, average=None)\n",
    "    per_class_scores = {f\"f1_{id2label[i]}\": score for i, score in enumerate(f1_per_class[\"f1\"])}\n",
    "    \n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score[\"accuracy\"],\n",
    "        \"f1_macro\": f1_score[\"f1\"],\n",
    "        **per_class_scores\n",
    "    }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07a3e1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "242146e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>Question</th>\n",
       "      <th>Response</th>\n",
       "      <th>tutor_class</th>\n",
       "      <th>label</th>\n",
       "      <th>context</th>\n",
       "      <th>fold</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>Sonnet</td>\n",
       "      <td>8</td>\n",
       "      <td>Now that we know the cost of 1 pound of meat i...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Tutor: Hi, could you please provide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Now that we know the cost of 1 pound of meat i...</td>\n",
       "      <td>Llama318B</td>\n",
       "      <td>5</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Tutor: Hi, could you please provide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>You're close, but I notice that you calculated...</td>\n",
       "      <td>Llama31405B</td>\n",
       "      <td>4</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Tutor: Hi, could you please provide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>That's correct. So, if 1 pound of meat costs $...</td>\n",
       "      <td>GPT4</td>\n",
       "      <td>3</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Tutor: Hi, could you please provide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221-362eb11a-f190-42a6-b2a4-985fafdcfa9e</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>It seems like you've calculated the cost as if...</td>\n",
       "      <td>Mistral</td>\n",
       "      <td>6</td>\n",
       "      <td>Great, you've correctly identified the cost of...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: Tutor: Hi, could you please provide ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            conversation_id  \\\n",
       "0  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "1  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "2  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "3  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "4  221-362eb11a-f190-42a6-b2a4-985fafdcfa9e   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Tutor: Hi, could you please provide a step-by-...   \n",
       "1  Tutor: Hi, could you please provide a step-by-...   \n",
       "2  Tutor: Hi, could you please provide a step-by-...   \n",
       "3  Tutor: Hi, could you please provide a step-by-...   \n",
       "4  Tutor: Hi, could you please provide a step-by-...   \n",
       "\n",
       "                                            Response  tutor_class  label  \\\n",
       "0  Great, you've correctly identified the cost of...       Sonnet      8   \n",
       "1  Now that we know the cost of 1 pound of meat i...    Llama318B      5   \n",
       "2  You're close, but I notice that you calculated...  Llama31405B      4   \n",
       "3  That's correct. So, if 1 pound of meat costs $...         GPT4      3   \n",
       "4  It seems like you've calculated the cost as if...      Mistral      6   \n",
       "\n",
       "                                             context  fold  \\\n",
       "0  Now that we know the cost of 1 pound of meat i...     0   \n",
       "1  Great, you've correctly identified the cost of...     0   \n",
       "2  Great, you've correctly identified the cost of...     0   \n",
       "3  Great, you've correctly identified the cost of...     0   \n",
       "4  Great, you've correctly identified the cost of...     0   \n",
       "\n",
       "                                               input  \n",
       "0  Question: Tutor: Hi, could you please provide ...  \n",
       "1  Question: Tutor: Hi, could you please provide ...  \n",
       "2  Question: Tutor: Hi, could you please provide ...  \n",
       "3  Question: Tutor: Hi, could you please provide ...  \n",
       "4  Question: Tutor: Hi, could you please provide ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# steps = 5 if DEBUG else 50\n",
    "\n",
    "# for fold in range(5):\n",
    "#     print(f'Fold {fold+1}/5')\n",
    "\n",
    "#     valid_df = train[train[\"fold\"] == fold].reset_index(drop=True)\n",
    "#     train_df = train[train[\"fold\"] != fold].reset_index(drop=True)\n",
    "    \n",
    "#     # from pandas\n",
    "#     train_ds = Dataset.from_pandas(train_df)\n",
    "#     valid_ds = Dataset.from_pandas(valid_df)\n",
    "#     remove = ['conversation_id', 'Question', 'Response', 'tutor_class','context', 'fold']\n",
    "#     train_tokenized_ds = train_ds.map(preprocess_function, batched=True,remove_columns=remove)\n",
    "#     valid_tokenized_ds = valid_ds.map(preprocess_function, batched=True,remove_columns=remove)\n",
    "    \n",
    "#     # Model\n",
    "    \n",
    "#     peft_config = LoraConfig(\n",
    "#         r=16,\n",
    "#         lora_alpha=32,\n",
    "#         lora_dropout=0.1,\n",
    "#         bias=\"none\",\n",
    "#         task_type=TaskType.SEQ_CLS,\n",
    "#         inference_mode=False,\n",
    "#         target_modules=[\n",
    "#             \"q_proj\",\n",
    "#             \"v_proj\"\n",
    "#         ],\n",
    "#     )\n",
    "\n",
    "#     bnb_config = BitsAndBytesConfig(\n",
    "#         load_in_4bit=True,\n",
    "#         bnb_4bit_quant_type=\"nf4\",\n",
    "#         bnb_4bit_use_double_quant=True,\n",
    "#         bnb_4bit_compute_dtype=torch.bfloat16\n",
    "#     )\n",
    "    \n",
    "#     base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "#         TARGET_MODEL,\n",
    "#         num_labels=len(id2label),\n",
    "#         quantization_config=bnb_config,\n",
    "#         id2label=id2label,          # Add this line\n",
    "#         label2id=label2id,          # Add this line\n",
    "#         device_map={\"\":0},\n",
    "#         # classifier_dropout = 0.4,\n",
    "#     )\n",
    "#     base_model.config.pretraining_tp = 1 # 1 is 7b\n",
    "#     base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "#     model = get_peft_model(base_model, peft_config)\n",
    "    \n",
    "#     training_args = TrainingArguments(\n",
    "#         output_dir=f\"///mnt/c/Personal/Competitions/BEA_2025/Zephyr/outputs/fold{fold}\",\n",
    "#         learning_rate=1e-4,\n",
    "#         per_device_train_batch_size=4,\n",
    "#         per_device_eval_batch_size=4,\n",
    "#         gradient_accumulation_steps=4,\n",
    "#         max_grad_norm= 0.5,#0.3,\n",
    "#         optim='paged_adamw_32bit',\n",
    "#         lr_scheduler_type=\"cosine\",\n",
    "#         num_train_epochs=10,\n",
    "#         weight_decay=0.0001,\n",
    "#         save_total_limit=1,\n",
    "#         eval_strategy=\"steps\",\n",
    "#         save_strategy=\"steps\",\n",
    "#         save_steps = 50,\n",
    "#         eval_steps = 50,\n",
    "#         logging_steps= 50,\n",
    "#         load_best_model_at_end=True,\n",
    "#         push_to_hub=False,\n",
    "#         warmup_steps=10,\n",
    "#         report_to='none', # if DEBUG else 'wandb',\n",
    "#         metric_for_best_model=\"f1_macro\",\n",
    "#         greater_is_better=True,\n",
    "#         overwrite_output_dir=True,\n",
    "#     )\n",
    "    \n",
    "#     trainer = Trainer(\n",
    "#         model=model,\n",
    "#         args=training_args,\n",
    "#         train_dataset=train_tokenized_ds,\n",
    "#         eval_dataset=valid_tokenized_ds,\n",
    "#         tokenizer=tokenizer,\n",
    "#         data_collator=data_collator,\n",
    "#         compute_metrics=compute_metrics,\n",
    "#         # callbacks=[EarlyStoppingCallback(early_stopping_patience=3)\n",
    "#     )\n",
    "    \n",
    "#     trainer.train()\n",
    "#     # validation \n",
    "#     pred_output = trainer.predict(valid_tokenized_ds)\n",
    "#     logits = pred_output.predictions\n",
    "#     probas = softmax(logits)\n",
    "#     np.save(f'///mnt/c/Personal/Competitions/BEA_2025/Zephyr/outputs/fold{fold}.npy', probas)\n",
    "\n",
    "#     del trainer, model, base_model\n",
    "#     import torch\n",
    "#     torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c40d0134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda cache clear\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get OOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2729ea34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Processing Functions\n",
    "def load_test_data(test_data_path='///mnt/c/Personal/Competitions/BEA_2025/data/mrbench_v3_testset.json'):\n",
    "    \"\"\"\n",
    "    Load development and (optionally) test datasets\n",
    "    \"\"\"    \n",
    "    # Load test data if provided\n",
    "    test_examples = []\n",
    "    test_data = None\n",
    "    if test_data_path:\n",
    "        with open(test_data_path, 'r',encoding=\"utf-8\") as f:\n",
    "            test_data = json.load(f)\n",
    "        \n",
    "        for dialogue in test_data:\n",
    "            conversation_id = dialogue[\"conversation_id\"]\n",
    "            conversation_history = dialogue[\"conversation_history\"]\n",
    "            \n",
    "            for tutor_id, tutor_data in dialogue[\"tutor_responses\"].items():\n",
    "                test_examples.append({\n",
    "                    \"conversation_id\": conversation_id,\n",
    "                    \"conversation_history\": conversation_history,\n",
    "                    \"tutor_response\": tutor_data[\"response\"],\n",
    "                    \"tutor_id\": tutor_id\n",
    "                })\n",
    "    \n",
    "    return test_examples, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b722239f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>Question</th>\n",
       "      <th>Response</th>\n",
       "      <th>tutor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1030-adb61831-0383-4e51-a673-ab978590f69b</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>It looks like you've done a great job figuring...</td>\n",
       "      <td>Tutor_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1030-adb61831-0383-4e51-a673-ab978590f69b</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>You've done a great job, but there's a small m...</td>\n",
       "      <td>Tutor_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1030-adb61831-0383-4e51-a673-ab978590f69b</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>OK, read the question again, and answer these ...</td>\n",
       "      <td>Tutor_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1030-adb61831-0383-4e51-a673-ab978590f69b</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Tutor: I see where you're coming from, but I t...</td>\n",
       "      <td>Tutor_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1030-adb61831-0383-4e51-a673-ab978590f69b</td>\n",
       "      <td>Tutor: Hi, could you please provide a step-by-...</td>\n",
       "      <td>Great job! Can you explain how you arrived at ...</td>\n",
       "      <td>Tutor_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             conversation_id  \\\n",
       "0  1030-adb61831-0383-4e51-a673-ab978590f69b   \n",
       "1  1030-adb61831-0383-4e51-a673-ab978590f69b   \n",
       "2  1030-adb61831-0383-4e51-a673-ab978590f69b   \n",
       "3  1030-adb61831-0383-4e51-a673-ab978590f69b   \n",
       "4  1030-adb61831-0383-4e51-a673-ab978590f69b   \n",
       "\n",
       "                                            Question  \\\n",
       "0  Tutor: Hi, could you please provide a step-by-...   \n",
       "1  Tutor: Hi, could you please provide a step-by-...   \n",
       "2  Tutor: Hi, could you please provide a step-by-...   \n",
       "3  Tutor: Hi, could you please provide a step-by-...   \n",
       "4  Tutor: Hi, could you please provide a step-by-...   \n",
       "\n",
       "                                            Response tutor_id  \n",
       "0  It looks like you've done a great job figuring...  Tutor_1  \n",
       "1  You've done a great job, but there's a small m...  Tutor_2  \n",
       "2  OK, read the question again, and answer these ...  Tutor_3  \n",
       "3  Tutor: I see where you're coming from, but I t...  Tutor_4  \n",
       "4  Great job! Can you explain how you arrived at ...  Tutor_5  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_examples,test_data = load_test_data()\n",
    "test = pd.DataFrame(test_examples)\n",
    "test.rename(columns={'conversation_history':'Question','tutor_response':'Response'},inplace=True)\n",
    "test.head()\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# train = pd.DataFrame(load_data())\n",
    "# train['target'] = train['tutor_class'].map(label2id)\n",
    "# train.rename(columns={'conversation_history':'Question','tutor_response':'Response'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 1547/1547 [00:01<00:00, 1002.87 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "test['input'] = \"Question: \" + test['Question'] + '; Answer: ' + test['Response'] #+ '; Context: ' + train[\"context\"]\n",
    "test_ds = Dataset.from_pandas(test)\n",
    "test_tokenized_ds = test_ds.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = [f'target_{i}' for i in range(len(id2label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Fold 0\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mistral to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n",
      "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Fetching 8 files: 100%|| 8/8 [19:55<00:00, 149.39s/it]   \n",
      "Loading checkpoint shards: 100%|| 8/8 [00:15<00:00,  1.90s/it]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-alpha and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_6146/2393846064.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Map: 100%|| 494/494 [00:00<00:00, 1158.99 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Fold 1\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mistral to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|| 8/8 [00:08<00:00,  1.02s/it]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-alpha and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_6146/2393846064.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Map: 100%|| 494/494 [00:00<00:00, 1317.62 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Fold 2\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mistral to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|| 8/8 [00:07<00:00,  1.04it/s]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-alpha and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_6146/2393846064.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Map: 100%|| 497/497 [00:00<00:00, 1335.71 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Fold 3\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mistral to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|| 8/8 [00:07<00:00,  1.05it/s]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-alpha and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_6146/2393846064.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Map: 100%|| 495/495 [00:00<00:00, 1315.14 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "Fold 4\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mistral to instantiate a model of type llama. This is not supported for all configurations of models and can yield errors.\n",
      "Loading checkpoint shards: 100%|| 8/8 [00:07<00:00,  1.06it/s]\n",
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at HuggingFaceH4/zephyr-7b-alpha and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_6146/2393846064.py:26: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Map: 100%|| 496/496 [00:00<00:00, 1253.78 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CKPTS =  [\"checkpoint-800\", \"checkpoint-1050\", \"checkpoint-650\", \"checkpoint-750\", \"checkpoint-1000\"]\n",
    "final_preds = []\n",
    "for fold, ckpt in enumerate(CKPTS):\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(f\"Fold {fold}\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    \n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "        TARGET_MODEL,\n",
    "        num_labels=len(id2label),\n",
    "        quantization_config=bnb_config,\n",
    "        device_map={\"\":0}\n",
    "    )\n",
    "    base_model.config.pretraining_tp = 1 # 1 is 7b\n",
    "    base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    model = PeftModel.from_pretrained(base_model, f\"///mnt/c/Personal/Competitions/BEA_2025/Zephyr/outputs/fold{fold}/{ckpt}\")\n",
    "    \n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "    # valid\n",
    "    valid_df = train[train[\"fold\"] == fold]\n",
    "    idxs = valid_df.index\n",
    "    valid_ds = Dataset.from_pandas(valid_df)\n",
    "    valid_tokenized_ds = valid_ds.map(preprocess_function, batched=True)\n",
    "    \n",
    "    pred_output = trainer.predict(valid_tokenized_ds)\n",
    "    logits = pred_output.predictions\n",
    "    probas = softmax(logits)\n",
    "    train.loc[idxs, target_cols] = probas\n",
    "    \n",
    "    # test\n",
    "    \n",
    "    pred_output = trainer.predict(test_tokenized_ds)\n",
    "    logits = pred_output.predictions\n",
    "    probas = softmax(logits)\n",
    "    final_preds.append(probas)\n",
    "\n",
    "    del model\n",
    "    del trainer\n",
    "    del base_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[target_cols] = np.mean(final_preds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c5e502b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajneesh/miniconda3/envs/hf_env/lib/python3.11/site-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
      "  has_large_values = (abs_vals > 1e6).any()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_0</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "      <th>target_5</th>\n",
       "      <th>target_6</th>\n",
       "      <th>target_7</th>\n",
       "      <th>target_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.177192e-04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.960464e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.072884e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.191036e-05</td>\n",
       "      <td>1.561642e-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.960464e-08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.152557e-07</td>\n",
       "      <td>9.536743e-06</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>1.829863e-05</td>\n",
       "      <td>1.430511e-06</td>\n",
       "      <td>5.364418e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.960464e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.576279e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1547 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target_0      target_1      target_2  target_3      target_4  \\\n",
       "0          0.0  0.000000e+00  1.000000e+00  0.000000  0.000000e+00   \n",
       "1          0.0  0.000000e+00  0.000000e+00  1.000000  0.000000e+00   \n",
       "2          1.0  0.000000e+00  1.072884e-06  0.000000  0.000000e+00   \n",
       "3          0.0  0.000000e+00  0.000000e+00  0.000000  1.000000e+00   \n",
       "4          0.0  5.960464e-08  0.000000e+00  0.000001  0.000000e+00   \n",
       "...        ...           ...           ...       ...           ...   \n",
       "1542       0.0  0.000000e+00  0.000000e+00  0.000000  2.384186e-07   \n",
       "1543       0.0  0.000000e+00  0.000000e+00  0.000000  0.000000e+00   \n",
       "1544       0.0  0.000000e+00  5.960464e-08  1.000000  0.000000e+00   \n",
       "1545       0.0  0.000000e+00  1.000000e+00  0.000000  0.000000e+00   \n",
       "1546       0.0  0.000000e+00  0.000000e+00  0.000000  3.576279e-07   \n",
       "\n",
       "          target_5      target_6      target_7  target_8  \n",
       "0     0.000000e+00  1.177192e-04  0.000000e+00  0.000000  \n",
       "1     5.960464e-08  0.000000e+00  0.000000e+00  0.000000  \n",
       "2     9.191036e-05  1.561642e-05  0.000000e+00  0.000000  \n",
       "3     0.000000e+00  0.000000e+00  0.000000e+00  0.000000  \n",
       "4     7.152557e-07  9.536743e-06  1.000000e+00  0.000117  \n",
       "...            ...           ...           ...       ...  \n",
       "1542  1.829863e-05  1.430511e-06  5.364418e-07  1.000000  \n",
       "1543  0.000000e+00  0.000000e+00  1.000000e+00  0.000000  \n",
       "1544  0.000000e+00  0.000000e+00  0.000000e+00  0.000000  \n",
       "1545  0.000000e+00  2.384186e-07  0.000000e+00  0.000000  \n",
       "1546  0.000000e+00  1.000000e+00  0.000000e+00  0.000000  \n",
       "\n",
       "[1547 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[target_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7b31085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       3\n",
       "2       0\n",
       "3       4\n",
       "4       7\n",
       "       ..\n",
       "1542    8\n",
       "1543    7\n",
       "1544    3\n",
       "1545    2\n",
       "1546    6\n",
       "Name: pred, Length: 1547, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['pred'] = test[target_cols].idxmax(axis=1).apply(lambda x: x.split(\"_\")[1])\n",
    "test['pred'] = test['pred'].astype(int)\n",
    "test['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02116bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('///mnt/c/Personal/Competitions/BEA_2025/Zephyr/outputs/test_probas.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39557ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = test['pred'].values\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57627f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "869e8a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = []\n",
    "unique_conversation_ids = list(ex[\"conversation_id\"] for ex in test_examples)\n",
    "\n",
    "for conversation_id in unique_conversation_ids:\n",
    "    conversation_data = next(d for d in test_data if d[\"conversation_id\"] == conversation_id)\n",
    "    submission_item = {\n",
    "        \"conversation_id\": conversation_id,\n",
    "        \"conversation_history\": conversation_data[\"conversation_history\"],\n",
    "        \"tutor_responses\": {}\n",
    "    }\n",
    "        \n",
    "    for tutor_id, tutor_data in conversation_data[\"tutor_responses\"].items():\n",
    "        # Find the corresponding prediction\n",
    "        idx = next(i for i, ex in enumerate(test_examples) \n",
    "                    if ex[\"conversation_id\"] == conversation_id and ex[\"tutor_id\"] == tutor_id)\n",
    "        \n",
    "        predicted_class = id2label[pred_labels[idx]]\n",
    "        \n",
    "        submission_item[\"tutor_responses\"][tutor_id] = {\n",
    "            \"response\": tutor_data[\"response\"],\n",
    "            \"annotation\": {\n",
    "                \"Tutor_Identification\": predicted_class\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    submission.append(submission_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ef9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "946222f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"///mnt/c/Personal/Competitions/BEA_2025/Zephyr/outputs\", \"predictions.json\"), \"w\") as f:\n",
    "    json.dump(submission, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca399c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
